# å¤šæ¨¡å‹æ”¯æŒä¸æ€§èƒ½ä¼˜åŒ–æ›´æ–°

## æ›´æ–°æ—¥æœŸ: 2026-01-30

## æ¦‚è¿°

æœ¬æ¬¡æ›´æ–°æ·»åŠ äº†å¤šç§æ¨¡å‹åç«¯æ”¯æŒï¼Œå¹¶æä¾›äº†è¯¦ç»†çš„æ€§èƒ½ä¼˜åŒ–æ–¹æ¡ˆï¼Œå¸®åŠ©ç”¨æˆ·æ ¹æ®å®é™…éœ€æ±‚é€‰æ‹©åˆé€‚çš„æ¨¡å‹å’Œä¼˜åŒ–ç­–ç•¥ã€‚

---

## ğŸ¯ ä¸»è¦æ–°åŠŸèƒ½

### 1. å¤šæ¨¡å‹åç«¯æ”¯æŒ

ç³»ç»Ÿç°åœ¨æ”¯æŒä¸‰ç§æ¨¡å‹åç«¯ï¼š

#### A. Ollama (é»˜è®¤)
- **ç‰¹ç‚¹**: æœ€ç®€å•ï¼Œå¼€ç®±å³ç”¨
- **é€‚ç”¨åœºæ™¯**: å¿«é€Ÿå¼€å§‹ï¼Œæœ¬åœ°æµ‹è¯•
- **ä½¿ç”¨æ–¹æ³•**:
  ```bash
  ollama pull qwen3-vl:4b
  python src/main.py --image-path /path --model qwen3-vl:4b
  ```

#### B. OpenAIå…¼å®¹API
- **ç‰¹ç‚¹**: æ”¯æŒvLLMã€LocalAIç­‰é«˜æ€§èƒ½æ¨ç†æœåŠ¡
- **é€‚ç”¨åœºæ™¯**: ç”Ÿäº§ç¯å¢ƒï¼Œé«˜å¹¶å‘éœ€æ±‚
- **ä½¿ç”¨æ–¹æ³•**:
  ```bash
  # å¯åŠ¨vLLMæœåŠ¡
  python -m vllm.entrypoints.openai.api_server \
    --model openbmb/MiniCPM-V-2_5 --port 8000

  # ä½¿ç”¨API
  python src/main.py \
    --image-path /path \
    --model minicpm-v \
    --model-type openai \
    --api-base http://localhost:8000
  ```

#### C. æœ¬åœ°æ¨¡å‹æ–‡ä»¶
- **ç‰¹ç‚¹**: ç›´æ¥åŠ è½½æ¨¡å‹ï¼Œå®Œå…¨ç¦»çº¿
- **é€‚ç”¨åœºæ™¯**: æ— ç½‘ç»œç¯å¢ƒï¼Œè‡ªå®šä¹‰æ¨¡å‹
- **ä½¿ç”¨æ–¹æ³•**:
  ```bash
  # ä¸‹è½½æ¨¡å‹
  git lfs clone https://huggingface.co/openbmb/MiniCPM-V-2_5

  # ä½¿ç”¨æœ¬åœ°æ¨¡å‹
  python src/main.py \
    --image-path /path \
    --model minicpm-v \
    --model-type local \
    --model-path ./MiniCPM-V-2_5
  ```

### 2. æ–°å¢é…ç½®å‚æ•°

#### å‘½ä»¤è¡Œå‚æ•°
```bash
--model-type {ollama,openai,local}  # æ¨¡å‹ç±»å‹
--model-path PATH                   # æœ¬åœ°æ¨¡å‹è·¯å¾„
--api-base URL                      # APIæœåŠ¡åœ°å€
--api-key KEY                       # APIå¯†é’¥
```

#### é…ç½®æ–‡ä»¶ç¤ºä¾‹
```yaml
# Ollamaé…ç½®
model: "qwen3-vl:4b"
model_type: "ollama"

# OpenAIå…¼å®¹APIé…ç½®
model: "qwen-vl-chat"
model_type: "openai"
api_base: "http://localhost:8000"
api_key: "your-key-if-needed"

# æœ¬åœ°æ¨¡å‹é…ç½®
model: "minicpm-v-2.5"
model_type: "local"
model_path: "/path/to/MiniCPM-V-2_5"
```

---

## ğŸ“Š æ¨èæ¨¡å‹

### å¿«é€Ÿå‚è€ƒè¡¨

| æ¨¡å‹ | å‚æ•°é‡ | æ˜¾å­˜ | é€Ÿåº¦ | ä¸­æ–‡ | æ¨èåœºæ™¯ |
|-----|--------|-----|------|------|---------|
| InternVL2-2B | 2B | 3GB | æå¿« | â­â­â­â­ | èµ„æºå—é™ |
| LLaVA-3B | 3B | 4GB | å¿« | â­â­ | è‹±æ–‡ä¸ºä¸» |
| **Qwen3-VL-4B** | 4.4B | 6GB | ä¸­ç­‰ | â­â­â­â­â­ | **æ¨èé¦–é€‰** |
| MiniCPM-V-2.5 | 2.8B | 4GB | å¿« | â­â­â­â­â­ | ä¸­æ–‡ä¼˜åŒ– |
| Qwen3-VL-8B | 8.8B | 10GB | æ…¢ | â­â­â­â­â­ | é«˜ç²¾åº¦ |

### é€‰æ‹©å»ºè®®

**æŒ‰èµ„æºé€‰æ‹©**:
- 4GBä»¥ä¸‹ â†’ InternVL2-2B, LLaVA-3B
- 4-6GB â†’ **Qwen3-VL-4B** (æ¨è), MiniCPM-V-2.5
- 6-10GB â†’ Qwen3-VL-8B, LLaVA-7B
- 10GB+ â†’ Qwen3-VL-8B, CogVLM2

**æŒ‰è¯­è¨€é€‰æ‹©**:
- ä¸­æ–‡ â†’ **Qwen3-VL** (å¼ºçƒˆæ¨è), MiniCPM-V
- è‹±æ–‡ â†’ LLaVA, InternVL2
- å¤šè¯­è¨€ â†’ Qwen3-VL-8B

**æŒ‰é€Ÿåº¦é€‰æ‹©**:
- æå¿«(1-2s/å¼ ) â†’ InternVL2-2B, LLaVA-3B
- å¿«é€Ÿ(2-5s/å¼ ) â†’ MiniCPM-V, **Qwen3-VL-4B**
- æ ‡å‡†(5-10s/å¼ ) â†’ Qwen3-VL-8B, LLaVA-7B

---

## âš¡ æ€§èƒ½ä¼˜åŒ–

### å½“å‰æ€§èƒ½é—®é¢˜
- åŸå§‹é€Ÿåº¦: ~28ç§’/å¼ 
- ä¸»è¦ç“¶é¢ˆ: å•çº¿ç¨‹å¤„ç† + æ¨¡å‹æ¨ç†æ…¢

### ä¼˜åŒ–æ–¹æ¡ˆå¯¹æ¯”

| ä¼˜åŒ–æ–¹æ¡ˆ | å®æ–½éš¾åº¦ | æ•ˆæœ | é€Ÿåº¦æå‡ |
|---------|---------|------|---------|
| æ¢å°æ¨¡å‹ | â­ ç®€å• | â­â­â­â­â­ | 9x |
| å‡å°å›¾ç‰‡ | â­ ç®€å• | â­â­â­ | 1.5x |
| 4è¿›ç¨‹å¹¶å‘ | â­â­â­ ä¸­ç­‰ | â­â­â­â­â­ | 4x |
| æ‰¹å¤„ç† | â­â­ ç®€å• | â­â­â­ | 2x |
| GPUåŠ é€Ÿ | â­â­ ä¸­ç­‰ | â­â­â­â­â­ | 10x |

### å¿«é€Ÿä¼˜åŒ–ï¼ˆç«‹å³å¯ç”¨ï¼‰

#### æ–¹æ¡ˆ1: ä½¿ç”¨å¿«é€Ÿæ¨¡å‹
```bash
# ä»28s/å¼  â†’ 3s/å¼  (9.3xæå‡)
ollama pull llava-v1.6:3b
python src/main.py --image-path /path --model llava-v1.6:3b
```

#### æ–¹æ¡ˆ2: å‡å°å›¾ç‰‡å°ºå¯¸
```bash
# é¢å¤–æå‡1.5x
python src/main.py --image-path /path --resize 256x256
```

#### æ–¹æ¡ˆ3: ç»„åˆä¼˜åŒ–
```bash
# ä»28s/å¼  â†’ 2s/å¼  (14xæå‡)
python src/main.py \
  --image-path /path \
  --model llava-v1.6:3b \
  --resize 256x256 \
  --tag-count 10
```

### é«˜çº§ä¼˜åŒ–ï¼ˆéœ€è¦ä»£ç ä¿®æ”¹ï¼‰

#### å¤šè¿›ç¨‹å¹¶å‘
```python
# é¢„æœŸ: ä»28s/å¼  â†’ 0.5s/å¼  (56xæå‡)
# TODO: å°†åœ¨ä¸‹ä¸ªç‰ˆæœ¬å®ç°
```

#### ä½¿ç”¨vLLMéƒ¨ç½²
```bash
# é«˜æ€§èƒ½æ¨ç†æœåŠ¡
pip install vllm
python -m vllm.entrypoints.openai.api_server \
  --model qwen3-vl:4b --port 8000

# å¯è·å¾—é¢å¤–30-50%æ€§èƒ½æå‡
```

### ç»¼åˆä¼˜åŒ–æ–¹æ¡ˆ

**æ–¹æ¡ˆA: æé€Ÿå¤„ç†**
```bash
# é€Ÿåº¦: ~1s/å¼ , è´¨é‡: ä¸­ç­‰
python src/main.py \
  --image-path /path \
  --model llava-v1.6:3b \
  --resize 256x256 \
  --tag-count 10 \
  --no-description
```

**æ–¹æ¡ˆB: å¹³è¡¡æ–¹æ¡ˆ** (æ¨è)
```bash
# é€Ÿåº¦: ~3-5s/å¼ , è´¨é‡: é«˜
python src/main.py \
  --image-path /path \
  --model qwen3-vl:4b \
  --resize 512x512 \
  --tag-count 20 \
  --description
```

**æ–¹æ¡ˆC: é«˜è´¨é‡**
```bash
# é€Ÿåº¦: ~10-15s/å¼ , è´¨é‡: å¾ˆé«˜
python src/main.py \
  --image-path /path \
  --model qwen3-vl:8b \
  --resize 768x768 \
  --tag-count 30 \
  --description
```

---

## ğŸ“ ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹1: ä½¿ç”¨Ollamaå¿«é€Ÿå¼€å§‹

```bash
# 1. å®‰è£…Ollama
curl https://ollama.ai/install.sh | sh

# 2. ä¸‹è½½æ¨¡å‹
ollama pull qwen3-vl:4b

# 3. å¤„ç†å›¾ç‰‡
python src/main.py \
  --image-path ~/Pictures \
  --model qwen3-vl:4b \
  --language zh \
  --tag-count 20
```

### ç¤ºä¾‹2: ä½¿ç”¨OpenAIå…¼å®¹API

```bash
# 1. å®‰è£…vLLM
pip install vllm

# 2. å¯åŠ¨APIæœåŠ¡
python -m vllm.entrypoints.openai.api_server \
  --model openbmb/MiniCPM-V-2_5 \
  --port 8000 \
  --gpu-memory-utilization 0.8

# 3. ä½¿ç”¨APIå¤„ç†
python src/main.py \
  --image-path ~/Pictures \
  --model minicpm-v \
  --model-type openai \
  --api-base http://localhost:8000 \
  --language zh
```

### ç¤ºä¾‹3: ä½¿ç”¨æœ¬åœ°æ¨¡å‹

```bash
# 1. ä¸‹è½½æ¨¡å‹
git lfs clone https://huggingface.co/openbmb/MiniCPM-V-2_5

# 2. å®‰è£…transformers
pip install transformers torch accelerate

# 3. ä½¿ç”¨æœ¬åœ°æ¨¡å‹
python src/main.py \
  --image-path ~/Pictures \
  --model minicpm-v-2.5 \
  --model-type local \
  --model-path ./MiniCPM-V-2_5 \
  --language zh
```

### ç¤ºä¾‹4: ä½¿ç”¨é…ç½®æ–‡ä»¶

åˆ›å»º `config.yaml`:
```yaml
model: "qwen3-vl:4b"
model_type: "ollama"
image_path: "/Users/user/Pictures"
resize: "512x512"
tag_count: 20
generate_description: true
language: "zh"
db_path: "./data/image_tags.db"
```

è¿è¡Œ:
```bash
python src/main.py --config config.yaml
```

---

## ğŸ”§ ä»£ç å˜æ›´

### ä¿®æ”¹çš„æ–‡ä»¶

1. **src/config.py**
   - æ·»åŠ  `model_type`, `model_path`, `api_base`, `api_key` é…ç½®
   - æ›´æ–°å‘½ä»¤è¡Œå‚æ•°å’ŒYAMLåŠ è½½

2. **src/models.py**
   - æ·»åŠ  `OpenAICompatibleModel` ç±»
   - æ·»åŠ  `LocalModel` ç±»
   - å°† `_parse_response` ç§»åˆ° `BaseModel`
   - æ›´æ–° `create_model` å·¥å‚å‡½æ•°

3. **src/tagging.py**
   - æ›´æ–° `process_image` å‡½æ•°ç­¾å
   - ä¼ é€’æ–°çš„æ¨¡å‹å‚æ•°

4. **src/main.py**
   - ä¼ é€’é…ç½®å‚æ•°åˆ°å¤„ç†å‡½æ•°

### æ–°å¢æ–‡ä»¶

1. **doc/model_recommendations.md**
   - æ¨èçš„æœ¬åœ°å°æ¨¡å‹è¯¦ç»†ä¿¡æ¯
   - æ¨¡å‹å¯¹æ¯”å’Œé€‰æ‹©å»ºè®®
   - éƒ¨ç½²æŒ‡å—

2. **doc/performance_optimization.md**
   - è¯¦ç»†çš„æ€§èƒ½ä¼˜åŒ–ç­–ç•¥
   - å®æ–½æ­¥éª¤å’Œé¢„æœŸæ•ˆæœ
   - ç›‘æ§å’Œè°ƒä¼˜å»ºè®®

3. **doc/multi_model_support_update.md** (æœ¬æ–‡ä»¶)
   - ç»¼åˆæ›´æ–°è¯´æ˜

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [æ¨¡å‹æ¨è](./model_recommendations.md) - è¯¦ç»†çš„æ¨¡å‹å¯¹æ¯”å’Œé€‰æ‹©æŒ‡å—
- [æ€§èƒ½ä¼˜åŒ–](./performance_optimization.md) - æ·±å…¥çš„æ€§èƒ½ä¼˜åŒ–ç­–ç•¥
- [CLAUDE.md](../CLAUDE.md) - é¡¹ç›®æ€»ä½“æ–‡æ¡£
- [æœ€è¿‘æ›´æ–°](./recent_updates.md) - ä¹‹å‰çš„æ›´æ–°è®°å½•

---

## â“ å¸¸è§é—®é¢˜

### Q1: æˆ‘åº”è¯¥é€‰æ‹©å“ªç§æ¨¡å‹åç«¯ï¼Ÿ
**A**:
- å¿«é€Ÿå¼€å§‹ â†’ Ollama (æœ€ç®€å•)
- ç”Ÿäº§ç¯å¢ƒ â†’ OpenAI API + vLLM (æ€§èƒ½æœ€å¥½)
- ç¦»çº¿ç¯å¢ƒ â†’ æœ¬åœ°æ¨¡å‹æ–‡ä»¶

### Q2: å¦‚ä½•æå‡å¤„ç†é€Ÿåº¦ï¼Ÿ
**A**: æŒ‰ä¼˜å…ˆçº§:
1. ä½¿ç”¨æ›´å¿«çš„æ¨¡å‹ (9xæå‡)
2. å‡å°å›¾ç‰‡å°ºå¯¸ (1.5xæå‡)
3. å®ç°å¤šè¿›ç¨‹ (4xæå‡)
4. ä½¿ç”¨GPUåŠ é€Ÿ (10xæå‡)

### Q3: ä¸­æ–‡æ•ˆæœä¸å¥½æ€ä¹ˆåŠï¼Ÿ
**A**: ä½¿ç”¨å›½äº§æ¨¡å‹:
- Qwen3-VL-4B (æ¨è)
- MiniCPM-V-2.5
- CogVLM2-4B

### Q4: æ˜¾å­˜ä¸è¶³æ€ä¹ˆåŠï¼Ÿ
**A**:
1. ä½¿ç”¨æ›´å°çš„æ¨¡å‹ (InternVL2-2B, LLaVA-3B)
2. ä½¿ç”¨é‡åŒ–ç‰ˆæœ¬ (Q4, Q8)
3. å‡å°å›¾ç‰‡å°ºå¯¸
4. ä½¿ç”¨CPUè¿è¡Œ (ä¼šæ…¢å¾ˆå¤š)

### Q5: å¦‚ä½•ä½¿ç”¨è‡ªå·±è®­ç»ƒçš„æ¨¡å‹ï¼Ÿ
**A**: ä½¿ç”¨localæ¨¡å¼:
```bash
python src/main.py \
  --model-type local \
  --model-path /path/to/your/model
```

---

## ğŸ¯ ä¸‹ä¸€æ­¥è®¡åˆ’

- [ ] å®ç°å¤šè¿›ç¨‹å¹¶å‘å¤„ç†
- [ ] æ·»åŠ æ‰¹å¤„ç†æ”¯æŒ
- [ ] æ”¯æŒæ›´å¤šæ¨¡å‹æ ¼å¼
- [ ] æ·»åŠ æ€§èƒ½ç›‘æ§å’Œç»Ÿè®¡
- [ ] æä¾›Web UIç•Œé¢

---

## ğŸ“ åé¦ˆä¸æ”¯æŒ

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·æäº¤Issueæˆ–Pull Requestã€‚

---

**æ›´æ–°å®Œæˆæ—¶é—´**: 2026-01-30
**ç‰ˆæœ¬**: v2.0
**ä¸»è¦è´¡çŒ®**: å¤šæ¨¡å‹æ”¯æŒ + æ€§èƒ½ä¼˜åŒ–æ–¹æ¡ˆ
